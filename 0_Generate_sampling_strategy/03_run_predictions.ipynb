{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711bb19-18b2-4e2b-bcc7-0a003a26790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import datacube\n",
    "import geopandas as gpd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import predict_xr, sklearn_flatten, sklearn_unflatten\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import rgb\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.temporal import temporal_statistics, xr_phenology\n",
    "from feature_extraction import feature_layers\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.measure import label, regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397076c-f54a-45a9-8c27-f18aeb2a5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82d240-8d20-4022-a675-d3610d4a2ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"results/ml_model.joblib\"\n",
    "sklearn_model = joblib.load(model_file)\n",
    "\n",
    "districts_file = \"data/cropping_propotion_by_district.geojson\"\n",
    "districts_gdf = gpd.read_file(districts_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90702415-ee6d-4a09-a9d8-53033a88d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8874b885-5125-41e8-b732-6ba18a38cda5",
   "metadata": {},
   "source": [
    "## Estimate proportion of each class per district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e42ee-a954-4d21-a6b3-f9a1faada186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to data cube\n",
    "dc = datacube.Datacube(app=\"crop_type_ml\")\n",
    "\n",
    "# Write a general query\n",
    "time = \"2021\"\n",
    "resolution = (-20, 20)\n",
    "output_crs = \"EPSG:6933\"\n",
    "\n",
    "query = {\n",
    "    \"time\": time,\n",
    "    \"resolution\": resolution,\n",
    "    \"output_crs\": output_crs,\n",
    "    \"dask_chunks\": {\"time\": 1, \"x\": 2000, \"y\": 2000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf1e6e-a1cc-41e7-b822-0528586aec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove areas smaller than 10 pixels\n",
    "\n",
    "def identify_and_filter_regions(prediction_xr, pixel_count_threshold=10, connectivity=1):\n",
    "    \n",
    "    # Convert to numpy for processing\n",
    "    predictions_np = prediction_xr.to_numpy()\n",
    "    \n",
    "    # Need to add one to all values to avoid a 0 class value (skimage treats as background)\n",
    "    predictions_np = predictions_np + np.ones(predictions_np.shape)\n",
    "    \n",
    "    # Set nan to 0 to be classified as the background\n",
    "    predictions_np = np.nan_to_num(predictions_np, nan=0)\n",
    "    \n",
    "    # Run the labelling step\n",
    "    # Use connectivity one to reduce the chance of keeping long connected roads/edges, and small connected patches\n",
    "    predictions_labelled = label(predictions_np, connectivity=connectivity, background=0)\n",
    "    \n",
    "    # Identify all regions where area is greater than pixel_count_threshold\n",
    "    labels_to_keep = []\n",
    "\n",
    "    for region in regionprops(predictions_labelled):\n",
    "        if region.area >= pixel_count_threshold:\n",
    "            labels_to_keep.append(region.label)\n",
    "            \n",
    "    # Create a mask corresponding to regions to keep\n",
    "    mask = np.isin(predictions_labelled, labels_to_keep)\n",
    "    \n",
    "    # Need to subtract one to all values to return to original class values\n",
    "    predictions_np = predictions_np - np.ones(predictions_np.shape) \n",
    "\n",
    "    # Mask the original prediction\n",
    "    prediction_masked = np.where(mask, predictions_np, np.nan)\n",
    "    \n",
    "    # Reformat as an xarray and return\n",
    "    prediction_masked_xr = xr.DataArray(prediction_masked, coords=prediction_xr.coords, dims=prediction_xr.dims, attrs=prediction_xr.attrs)\n",
    "    \n",
    "    return prediction_masked_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd5e26-d5be-4214-a78c-fb03d051d403",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest_gdf = districts_gdf\n",
    "district_column = \"DISTRICT\"\n",
    "n_classes = sklearn_model.cluster_centers_.shape[0]\n",
    "\n",
    "classes = [f\"class_{i}\" for i in range(n_classes)]\n",
    "\n",
    "for index, district in area_of_interest_gdf.iterrows():\n",
    "    \n",
    "    # Set up geometry\n",
    "    district_name = district[district_column]\n",
    "    print(f\"Processing {district_name}\")\n",
    "    \n",
    "    # Check if district has already been processed. If so, skip\n",
    "    output_filename = f\"data/district_{district_name}_cropping_propotion_by_class_filtered.csv\"\n",
    "    if os.path.exists(output_filename):\n",
    "        print(\"Completed; Skipping\")\n",
    "        continue\n",
    "\n",
    "    # set up query based on district polygon\n",
    "    geom = geometry.Geometry(geom=district.geometry, crs=area_of_interest_gdf.crs)\n",
    "    q = {\"geopolygon\": geom}\n",
    "\n",
    "    # merge polygon query with user supplied query params\n",
    "    query.update(q)\n",
    "\n",
    "    # Load the feature data\n",
    "    print(\"    Loading feature data\")\n",
    "    feature_data = feature_layers(query).squeeze(dim=\"time\", drop=True).load()\n",
    "\n",
    "    # Load the crop mask\n",
    "    crop_mask_query = query.copy()\n",
    "    crop_mask_query.update({\"time\": \"2019\"})\n",
    "\n",
    "    # Load the crop mask\n",
    "    print(\"    Loading crop_mask\")\n",
    "    crop_mask = dc.load(product=\"crop_mask_southeast\", **crop_mask_query).load()\n",
    "    \n",
    "    # Create a mask for the district\n",
    "    district_mask = xr_rasterize(\n",
    "        gdf=gpd.GeoDataFrame({\"DISTRICT\": [district_name], \"geometry\": [district.geometry]}, crs=area_of_interest_gdf.crs),\n",
    "        da=feature_data,\n",
    "        transform=feature_data.geobox.transform,\n",
    "        crs=\"EPSG:6933\",\n",
    "    )\n",
    "\n",
    "    # Clip the feature data to the crop mask and the district mask:\n",
    "    district_crop_data = feature_data.where((crop_mask.filtered == 1) & (district_mask==1)).squeeze()\n",
    "\n",
    "    # Predict the classes\n",
    "    district_crop_class = predict_xr(sklearn_model, district_crop_data, persist=True)\n",
    "\n",
    "    # Mask the predictions to\n",
    "    print(\"    Preparing predictions\")\n",
    "    district_crop_class_masked = (\n",
    "        district_crop_class.Predictions.where((crop_mask.filtered == 1) & (district_mask==1))\n",
    "    )\n",
    "    \n",
    "    district_crop_class_masked = (district_crop_class_masked\n",
    "        .squeeze()\n",
    "        .assign_attrs({\"crs\": \"EPSG:6933\"})\n",
    "        .rename(\"class\")\n",
    "        .drop([\"time\", \"spatial_ref\"])\n",
    "    )\n",
    "    \n",
    "    # Filter small regions\n",
    "    print(\"    Filtering regions with fewer than 10 pixels (at connectivity=1)\")\n",
    "    district_crop_class_masked_filtered = identify_and_filter_regions(district_crop_class_masked)\n",
    "    \n",
    "    # Write to cog\n",
    "    prediction_file = f\"data/district_{district_name}_prediction_filtered.tif\"\n",
    "    print(f\"    Writing predictions to {prediction_file}\")\n",
    "    write_cog(\n",
    "        district_crop_class_masked_filtered,\n",
    "        fname=prediction_file,\n",
    "        overwrite=True,\n",
    "    )\n",
    "\n",
    "    # Loop through each class\n",
    "    district_class_counts = []\n",
    "\n",
    "    total_pixels = 0\n",
    "\n",
    "    print(\"    Counting pixels in each class\")\n",
    "    for i in range(n_classes):\n",
    "        count = district_crop_class_masked_filtered.where(district_crop_class_masked_filtered == i).count().item()\n",
    "        district_class_counts.append(count)\n",
    "\n",
    "        total_pixels += count\n",
    "        \n",
    "    district_crop_propotions_df = pd.DataFrame({'class': classes, 'count': district_class_counts})\n",
    "    district_crop_propotions_df[\"proportion\"] = district_crop_propotions_df[\"count\"]/total_pixels\n",
    "    \n",
    "    proportion_file = f\"data/district_{district_name}_cropping_propotion_by_class_filtered.csv\"\n",
    "    district_crop_propotions_df.to_csv(proportion_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
